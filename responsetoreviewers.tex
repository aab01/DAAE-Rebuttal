\documentclass{article}
\usepackage[utf8]{inputenc}

\title{TNNLS DAAE Addressing Reviews}
\author{ac2211 }
\date{October 2017}

\usepackage{color,soul}
\usepackage{hyperref}

\begin{document}

\maketitle
\section*{Introduction}
We would like to thank the reviewers for the clear efforts put into reading, understanding and providing a critique of this draft. We apologise for the missing final page of references, which was an error that crept in on uploading the manuscript.  The {\em original} final page is attached as an appendix to this document, as well as the revised manuscript. \\

\section*{Reviewer: 1}
\subsection*{Comments to the Author}
{\color{blue} The paper proposes DAAEs, which use adversarial training to match the posterior distribution to the prior for a denoising autoencoder. The proposed approach is like a combination of existing methods like DAEs, AAEs and DVAEs.}\\

Whilst we do not question the relation of the proposed DAAE and iDAAE to other techniques, we believe that both represent a contribution.  To emphasise the contributions, we have now modified Figure 1 {\color{red} to show our models in another colour, } so that the contributions that we propose are clearer, and are seen relative to relevant work.  These differences of the DAAE and iDAAE to the DAEs, the VAE, DVAE and AAE are sufficient to warrant study, and in the revised paper, we provide a much more extensive set of experiments.\\

{\color{red} should we refer to the experiments now? since it does not directly address the comment. And we say it next}

{\color{blue} Some benefits of the proposed method are highlighted when presenting the method but not well supported in the experiments. }\\

We agree with this statement, and have now performed much more extensive experiments in the widely used celebA dataset. {\color{red} We have performed attribute classification experiments and achieve competative or supervior perfromance in several categories, compared to the VAE, beta-VAE and DIP-VAE.}\\

%\hl{We have introduced tests on robustness to specific image transforms for classification, and we believe these reflect real and non-trivial performance benefits.} \\

{\color{blue} The writing of the paper should be further improved as there is a lot of unclear statements and confusing notations throughout the paper (I list some major issues in the detailed comments.).} \\

We are very grateful to the reviewer for this comment, and the effort spent on identifying exactly were there are opportunities for improvement. We have tried to improve the writing generally, and to address the specific issues identified (see, for example, the next section). \\

{\color{blue} The criteria of evaluation and datasets in the experiment part are not satisfactory. The results are not sufficient for a good publication. I suggest the authors proofread and rewrite the paper and provide strong experimental results to support the motivation of the method.}\\

We have {\color{red} moved} the MNIST results to an appendix. We now include experiments on the CelebA face database.  These experiments include image generation (synthesis) which we believe are competitive, and which strengthen the comparison of both the proposed iDAAE and DAAE to comparable methods. In addition, we demonstrate classification of \hl{attributes} from latent space representations. We provide direct comparisons of the DAAE and iDAAE performance for classification with the AAE {\color{red} as well as the VAE, beta-VAE and DIP-VAE, achieving competative or superior performace on most attributes}.\\

{\color{red} `which we believe are competative` -- I do not think we can say this about the synthesis -- we can say it about the classification tho!}

We have tried to improve the writing generally, and to address the specific issues identified (see, for example, the next section). Extensive proofreading has been performed.

\subsection*{Detailed comments}

{\color{blue}
The paragraph ``Two broad approaches ...'' (Line 55-60, Column 1, Page 1) should be clarified. For 1), it is better to include some references. }  \\

We have added references to three papers that use the denoising criterion to train autoencoders.
These are {\color{red} vincent2010stacked, bengio2013generalized, vincent2008extracting}.  The sentence now reads:\\

{\color{red} Two broad approaches to learning state-of-the-art generative models that do not require labelled training data include: 1) introduction of a denoising criterion \{vincent2010stacked, bengio2013generalized,  vincent2008extracting\} -- where the model learns to reconstruct clean samples from corrupted ones;}\\

{\color{blue} For 2), both VAEs [6] and GANs [13] use a latent space with a known prior distribution for generation. However, GANs [13] do not regularize the latent space while VAEs [6] do but directly for the training of the recognition model instead of the generative model.}\\

We agree with this. Our initial intention in writing the sentence was to point out that VAEs and GANs both have some constraints on latent space: GANs through the latent space arising from noise sources, and VAEs in the sense of having priors placed on latent space. We realise that this is potentially misleading, so we have removed the phrase ``latent space with a {\color{red} known} prior distribution''. \\

{\color{blue} The author should be careful about the correctness of ``regularisation ... [1], [9], [13] or using … [6], [9], [13]'' and clarify the writing.} \\

We agree that the sentence was confusing, particulary with regard to the use of the term ``regularisation'' and the choice of references. We have now altered the sentence to read:

``regularisation of the latent space to match a prior {\color{red} \{ kingma2013auto, makhzani2015adversarial \}}''

We would like to make an additional comment here: including GANs was not necessary for us to convey the key ideas: that denoising and regularisation are core components of state of the art generative models. \\


{\color{blue}
The sentences ``Autoencoders introduce'' (Line 47-60, Column 1, Page 2) should be rewritten. On one hand, not all of the autoencoders are probabilistic. In contrary, for ``autoencoders'', people refers to the deterministic autoencoders by default.}\\

We agree that not all autoencoders are probabilistic, but they are often referred to in a probabilistic framework, and we add the citation [9] Kingma et al to qualify this. In fact, this is exactly how VAE's in [9] were first introduced.  We provide the quotation from [9] for context:
    
    \begin{quote}
       In this paper we will therefore also refer to the recognition model $q_\phi(z|x)$ as a probabilistic encoder, since given a datapoint x it produces a distribution (e.g. a Gaussian) over the possible values of the code z from which the datapoint x could have been generated. In a similar vein we will refer to $p_\theta(x|z)$ as a probabilistic decoder, since given a code z it produces a distribution over the possible corresponding values of x.
    \end{quote}

We have purposefully used notation consistent with Kingma et al. [9]. Of course, in a sense, probabilistic autoencoders generalise (and include, as a clear subset) non-probabilistic ones, and our intention was to be {\em general}. \\

 {\color{blue}I also note that subsection C introduces VAEs again, which may be redundant. On the other hand, both the encoders and decoders in VAEs are trained jointly instead of ``first learning … form a training set … trained in a supervised fashion.'' I seriously suggest the authors to present the literature carefully and precisely.}\\

 We are -- of course -- aware that the encoder and decoder are trained jointly in \textbf{most} generative models. Indeed, we did say this at the end of Section 1A (our original submission):
    \begin{quote}
        In some situations the encoding distribution is chosen rather than learned, in other  situations the encoder and decoder are learned simultaneously...
    \end{quote}
Our reason for explicitly pointing this out is to generalise to the case where the encoding process, was {\em not} learned. Doing this -- which we agree may have been misleading -- allows us to include a suggestion (by Bengio, perhaps not very widely referred to) in which encoding is treated as a {\em local corruption process} which is {\em not} learned.  From our original submission, at the Top of 1B:
    \begin{quote}
        Bengio  et  al.  [4]  treat  the  encoding  process  as  a  local corruption  process,  that  does  not  need  to  be  learned.
    \end{quote}
In [4], there is no latent space in the same sense as that for VAEs or GANs. To improve the clarity and visibility of this idea, we have added references {\color{red} has been checked}:
\begin{quote}
    In some situations the encoding distribution is chosen rather than learned \{bengio2013generalized\}, in other situations the encoder and decoder are learned simultaneously \{kingma2013auto, makhzani2015adversarial, im2015denoising\}
\end{quote}
Why did we do this?  It allowed us to treat encoding in the most general way, so that we can bring the approach suggested in [4] under the same umbrella as other models. Doing this also allows us to acknowledge Bengio's DAE, but also to distinguish between the ``corruption'' of that model and the noise process of our proposed DAAE more clearly. For example, the approach of [4] does not explicitly define a latent space.  It is also worth pointing out that taking Bengio's corruption process [4] to the extreme is equivalent to having a latent representation which is Gaussian noise \{bachman2015variational\}; so this way of thinking seems to be self-consistent.


{\color{blue}
I’m confused by the reconstruction cost function (Line 50-54, Column 1, Page 4). The normal definition should be $E_{x\sim p(x)} E_{z\sim q_{\phi}(z|x)} log p(x | z)$ following VAEs. The author skip this equation but directly present one with Monte Carlo approximation by sampling x and z. }\\

The cost function $E_{x\sim p(x)} E_{z\sim q_\phi(z|x)} \log p(x | z)$ is {\em not} used in denoising autoencoders: it is typically used in VAEs and AAEs: this expression lacks a corruption process. Because the writing in this section refers to denoising autoencoders, this is not the right expression for $L_{rec}$.\\

{\color{blue} However, as x is sampled, there should not be a term of $p(x_i)$ in the equation (it should be 1/N, which already exists.). Another typo is “$log p(x_i | z_i)$” instead of “$log p(x | z_i)$”. Did I miss something? It should be clarified.}\\

Thanks for spotting this!  There was indeed an extra $i$ subscript in the Equation. However, to ensure clarity we have also rewritten the equation and ammended the text immediately below it to avoid potential ambiguity:
\[ \mathcal{L}_{rec} = \frac{1}{N}\sum_{i=0}^{N-1} \log p_\theta(x|z_i)\]
where the $z_i$ are obtained by the folling sampling process $x_{i=0...N-1} \sim p(x)$, $\tilde{x}_i \sim c(\tilde{x}|x_i)$, $z_i \sim q_\phi(z|\tilde{x}_i)$, and $p(x)$ is distribution of the training data.\\


{\color{blue}
The experiments are restricted on simple datasets, which are out of date. In contrary, as one of the main baselines, AAEs are evaluated on faces and color images. Besides, the image quality in this paper is far from state-of-the-art on the simple datasets.}\\

Our choice of datasets was explained in Section VI.B of the original submission.  We acknowledge that in one sense the data might be regarded as simple, but please note that 
\begin{itemize}
    \item the sprites dataset (of the orignal paper) is a {\em colour} dataset
    \item the AAE paper \cite{} presented results on MNIST, SVHN and heavily cropped faces of the Fray dataset, none of which are in colour.
    \item Kingma's VAE paper presents results on Fray and MNIST.
    \item the DVAE paper contains no images at all
\end{itemize}. 
Notwithstanding this, in the revised paper, we have now included synthesized examples of colour faces. For ease of reference, we show some examples of synthesized images below:\\

\begin{figure}

\end{figure}


In addition, we have introduced new experiments in facial expression classification based on colour faces; these were not present in the original paper.  These experiments are to be found in \hl{Section XX}.

{\color{blue}
The reconstruction results are not so interesting and some of them can be removed. In addition, the reconstruction results on MNIST and Omniglot are inconsistent, which should be analysed in depth. Current version does not provide insight for the phenomena.}\\

We are not sure we understand \hl{the point}.  We have however significantly increased the evaluation, both by demonstrating high-quality synthesis results (see, for exampe XX and YY), and by including evaluation of robustness (shift tolerance and classification performance from latent space).\\

{\color{blue}
The Parzen window estimator is not reliable [1]. It is better to use the methods proposed in [2] or [3] to compare the generative ability quantitatively.}\\

We were aware of the literature [1] and did cite Theis, in the last paragraph VII.E.- unfortunately in the uploading process the last page of references was not accidentally omitted. In the original submission paper, we had the following paragraph:\\

\begin{quote} Finally, evaluating generated samples is challenging: log-likelihood is not always reliable cite\{theis2015note\}, and qualitative analysis is subjective. For this reason, we provided both quantitative and qualitative results to communicate the benefits of introducing Markov chain sampling when a trained DAAE, and the advantages of iDAAEs over AAEs. 
\end{quote}\\
and these were the corresponding references:

[1] Theis L, Oord A, Bethge M. A note on the evaluation of generative models[J]. arXiv preprint arXiv:1511.01844, 2015.\newline
[2] Salimans T, Goodfellow I, Zaremba W, et al. Improved techniques for training gans[C]//Advances in Neural Information Processing Systems. 2016: 2234-2242.\newline
[3] Wu Y, Burda Y, Salakhutdinov R, et al. On the quantitative analysis of decoder-based generative models[J]. arXiv preprint arXiv:1611.04273, 2016.\newline

For this reason, we provided both quantitative and qualitative results to communicate the benefits of introducing Markov chain sampling with a DAAE, and the advantages of iDAAEs over AAEs.  We hope that the revised version of the paper -- with larger face synthesis and experiments on \hl{expression} classification -- further emphasises these points. \\

We would also like to point, once again, to the demonstration of the Omniglot dataset, which contains examples of alphabets that are completely absent from the training data. We have since shifted the classification results into one table, so that it is clear that there are separate datasets in Omniglot. Notably (and this is something that enforces the reviewers point):

\begin{itemize}
    \item if we evaluate log-likelihood on samples from alphabets that are different to those in the training data, the log likelihood gets worse with an extended number of iterations
    \item if we evaluate log-likelihood on samples from alphabets similar to those in the training data the likelihood get better with an extended number iterations.
\end{itemize}


{\color{blue}
The main advantage of the proposed method over DVAEs is providing the flexibility to choose complicated priors and posteriors. However, I do not observe any practical benefit of using mixture of Gaussian instead of high-dimensional Gaussian priors in terms of reconstruction error, log likelihood or sample quality. So, the motivation of the method is not well supported according to the current experiments.}\\

Good question!  The reason is that by supporting mixtures of Gaussians, one can encourage latent space to have an organisation that mirrors the semantic aspects that one wishes to represent in the data. To be clear, we do not suggest {\em replacing} high-dimensional Gaussians, but instead suggest using mixtures of high-dimensional Gaussians.   To take a very simple case, if we have an observation space that is clearly bimodal (containing dogs and cats), then it would seem imminently sensible that latent space should have a distribution that reflects this \hl{need an example for which $z_k$ ``label'' separability is a bad idea vs multimodal version}.\\

\begin{itemize}
    \item \{TODO...\}
    \item cite some literature
    \item not enough room for all experiments.
    \item Do for faces!
\end{itemize}

{\color{blue}
As for the classification, the results should be compared with other unsupervised learning methods with adversarial losses like [4].

[4] Donahue J, Krähenbühl P, Darrell T. Adversarial feature learning[J]. arXiv preprint arXiv:1605.09782, 2016.}

\begin{itemize}
    \item \{4\} Do NN1 classification for MNIST and semi-supervised learning for ImageNet
    \item We chose not to do semi-supervised learning because we wanted to evaluated the latent representation learned - which is best ahcieved using NN or training an SVM on top of the representation
    \item Our motivation was learning in the absence of larger amounts of labelled training data - for this the Omniglot dataset is ideal - since it has only 20 examples per class.
\end{itemize}

{\color{blue}
Though the sampling method proposed do not rely on a given data but it is still an iterative one, which is less efficient than VAEs and GANs. Indeed, throughout this paper, I find no evidence that the proposed method can outperform VAEs and GANs, which are simple, effective and well-known.}\\

In the revised paper, we have significantly different 
\begin{itemize}
    \item In this paper we identify an issue related to drawing samples from these models, which also applies to the DVAE
    \item We propose methods to overcome these issues, and explain why it may be difficult to obtain visually plausible image samples from some denoinsing autoencoders.
\end{itemize}


Minor things: \newline

{\color{blue}
Some references are missing. For instance, [23] is not found in the reference list.}\\

Unfortunately in the submission process the last page of references were cut off. They are now included.\\

{\color{blue}
The notations should be explained in detail, e.g. $f_\phi$, $p_\theta$.} \\

We believe the reviewer is referring to $p_\phi$ and $p_\theta$ or possibly $f_\psi$? There is no $f_\phi$ in this paper. Notations $p_\phi$ and $p_\theta$ might be used in different ways in the literature, and so when we introduce them, we cite the work of Kingma et al.\\

\begin{quote}
    learning a \textit{probabilistic encoder} cite\{kingma2013auto\}, $q_\phi(z|x)$, conditioned on observed samples, and a second \textit{probabilistic decoder} cite\{kingma2013auto\},
\end{quote} 

{\color{blue}
It is better to include some instances in Line 4-9, Column 2, Page2.}\\

{\color{blue}
I have no idea why the word “simple” in Line 19, Column 1, Page 3 is bold.}\newline

We were trying to emphasise ...., but we agree that this was unnecessary.  Removed.

{\color{blue}
It should be $\tilde q_\phi(z|x)$ instead of $\tilde q_\phi(x|z)$ in the last term of the equation in Line 34-35, Column 1 Page 3. }


\section{Reviewer: 2}

Comments to the Author
{\color{blue}
This work introduces two new types of denoising autoencoders, DAAE and iDAAE. The authors propose an adversarial training methodology to address the analytical intractability associated with including a denoising criterion in the variational cost function. While sufficient theoretical development is provided, additional work is needed to validate the proposed solutions empirically. I suggest that the authors address the following comments in order to improve this manuscript:}\newline

{\color{blue}
(1) What process did you follow to select the parameters for your models? It would be helpful to outline a strategy for choosing at least some of the key parameters, such as the size of the encoding space. }\newline
\begin{itemize}
    \item We used similar architectures to those in previous work for MNIST we used the same architecture as the AAE {Makhzani}.
    \item We modified this network for the Omniglot dataset, as discussed (Section VI.C.2):
    \begin{quote}
        Compared  to  the  networks  used  for  MNIST,  deeper networks  were  needed  in  order  for  the  loss  functions  to converge.
    \end{quote}
    \item We also modified the network of makhzani et al. for the sprite dataset:
    \begin{quote}
        For  the  decoder,  we  found  that  it  was  necessary  to  use  a 3-layer  fully  connected  neural  network  in  order  to  capture the  complexity  of  the  sprite  dataset.  However,  by  comparing training and test data reconstruction error during training, we found that using 1000 neurons in each layer led to over-fitting. Rather, we used a 3-layer fully connected neural network with 1000 neurons  in  the  first  layer  and 500 in  each  of  the  last layers.
    \end{quote}
    
\end{itemize}

{\color{blue}
(2) In Section V.A., please indicate the specific nonlinear activation functions you used in the intermediate layers of the network.}\newline

\begin{itemize}
    \item We use ReLU's
    \item We have included this as follows:
    \begin{quote}
        Rectifying Linear Units (ReLU) were used between all intermediate layers to encourage the networks to learn representations that capture multi-modal distributions. \newline
        ... \newline
        Intermediate layers of the network have ReLU activation functions to encourage the network to capture highly non-linear relations
    \end{quote}
\end{itemize}

{\color{blue}
(3) How sensitive are your models to changes in the parameter configuration? Is extensive parameter tuning required in order to achieve your reported results?}\newline

\begin{itemize}
    \item We did very little hyper parameter tuning. To make our comparisons as "fair" as possible we use the same hyper parameters for each experiment, and the choice for hyper-parameters was based on previous work:
    
    \begin{quote}
        In  order  to  compare  models trained on the same datasets, the same network architectures, batch size, learning rate, annealing rate, size of latent code and number of epochs is used for each
    \end{quote}
    
    \item TODO add citations to AAE for using the same architecture
    \item  TODO add citation to  
\end{itemize}

{\color{blue}
(4) You use a standard AAE as a benchmark for evaluating DAAE and iDAAE. It would be helpful to also include a regular autoencoder in your results for reference.}\newline

\begin{itemize}
    \item Regular autoencoders may not be used for sample synthesis because the latent distribution is not known - only a denoising variant may be used to synthesise samples
    \item We could have used an autoencoder for classification TODO? 
    \item We chose to compare to state of art.
\end{itemize}

{\color{blue}
(5) All of your experimental results use image datasets. Can you comment on the applicability \& expected performance of your methods on non-image data?}\newline

{\color{blue}
(6) In Section VI.D., you state "The reconstruction is evaluated by computing the mean squared error between the reconstruction and the original sample." Please clarify if "original sample" means the uncorrupted withheld test data. The uncorrupted data should be used to evaluate the quality of the reconstruction across all methods in order to provide an accurate comparison, regardless of whether the samples were corrupted going into the model.}\newline

\begin{itemize}
    \item We agree - all experiments should have been performed on uncorrupted data
    \item We have now done this TODO!
\end{itemize}

{\color{blue}
(7) There is no comparison in training times between the different methods. A comparison of both performance and training complexity is needed to evaluate the practical merits of this work. Ideally this should be provided for all of the methods you considered as well as a standard autoencoder without regularisation or adversarial training. This is particularly important to consider given how close your proposed methods are in performance to much simpler methods like PCA.}\newline

\begin{itemize}
    \item Standard autoencoders may not be used for sample synthesis
    \item TODO?
\end{itemize}

\section{Reviewer: 3}

Comments to the Author
The paper introduces two denoising adversarial autoencoders combining concepts from denoising and adversarial autoencoders known in the literature. 

The paper presents an interesting approach for unsupervised representation learning, combining advantages of previously proposed models. The authors also address the issue of generating samples when a posterior of a latent representation based on corrupted input is matched to prior rather than posterior based on uncorrupted input. The authors propose a Markov Chain to generate samples in this case and provide theoretical guarantees for this although here they highly rely on the previous work by Bengio et al 2013, 2014. 
{\color{blue}
The main concerns regarding the paper are about the experimental section. Although the authors provide a very thorough evaluation of their methods on three different datasets for three different tasks there are still some moments that could potentially improve the value of the paper. First of all, the comparison is provided only with respect to the adversarial autoencoder. It is a very interesting comparison as it allows to empirically evaluate the influence of denoising training of the adversarial autoencoder. On the other hand the proposed methods can be considered as adversarial extension of denoising autoencoders, and it would be interesting to see how adversarial learning to match the prior works in comparison to Kullback-Leibler minimisation used in DVAE, for example.}

\begin{itemize}
    \item It has already be shown by Makhzani, the benefits of using adversarial rather than KL to match a prior in the case of AAE and VAE.
    \item For this reason we did not make experiments comparing DVAE with DAAE a priority, rather we focused on comparing DAAE and AAE
\end{itemize}

{\color{blue}
The second concern regarding the experimental setup is about choice of the prior used in the experiments. Except DAAE with 2D 10-GMM prior that shows poor results and is outperformed by all the competitors the experiments are conducted with Gaussian prior that could have been trained with DVAE and VAE. The main motivation of the proposed methods in compariosn to DVAE claimed by the authors was the possibility of using different more complex priors. It would be good to see this in the experiments.}\newline 


{\color{blue}(The other drawback mentioned for DVAE that is non-trivial synthesis is also valid for the proposed DAAE but successfully overcome by the authors and could have been overcome for DVAE)}. \newline

\begin{itemize}
    \item Yes, exactly. Although we did not explore this further, since we were focusing on AAE, this could be an avenue for future work. We have added this to the Future Work section of our paper to hilight the significance of our work for DVAEs as well as DAAEs.
    \begin{quote}
        6) applying our proposed sampling process to the DVAE \cite{im2015denoising} - for which sampling is non-trivial for the same reasons discussed for the DAAE
    \end{quote}
\end{itemize}


Other comments: \newline
{\color{blue}
1. The first two paragraphs of the introduction are general and do not mention anything about neural networks although all the references are for papers related to NN. It would be better to either mention in the text that the authors are talking about NNs or to add some not NN references.}

\begin{itemize}
    \item We chose to present the model and theory in a more general framework and then show that neural networks may be used for implementation.
    
    In the last paragraph of section IV.B. we say:
    \begin{quote}
    The analyses of Sections \ref{DAA} and \ref{synthesis} are deliberately general: they do not rely on any specific implementation choice (e.g. particles, artificial neural networks, or parametrised forms of distribution) to capture the model distributions.
    \end{quote}
At the start of the next section, section V.A. we talk about the implementation using neural networks.
\begin{quote}
    Under the autoencoder framework, $E_\phi(x)$ is the encoder and $R_\theta(z)$ is the decoder. We used fully connected neural networks for both the encoder and decoder.
\end{quote}

\item In figure 1, on page 1 where we present our model, the caption says:
\begin{quote}
    Arrows in this diagram represent mappings implemented using trained neural networks.
\end{quote}
we refer to Figure 1, multiple times in the Introduction.

\end{itemize}

{\color{blue}
2. In the list of references there are only 21 papers whereas in the text works are cited upto 24} \newline

In the submission process the last page was unintentionally left out. The rest of the references have now been included. \newline

{\color{blue}
3. Section I.A First paragraph. "... there is a ground truth label for every training image." - It has not been specified before that classification of images only is considered.} \newline

This has been replaced by:
\begin{quote}
    because there is a ground truth label for every training data sample.
\end{quote}
We deliberately keep the method general. \newline

{\color{blue}
4. Section I.A Autoencoders do not have to be probabilistic generally speaking. It would be better to mention it and probabilistic interpretation is considered here.}

\begin{itemize}
    \item It is advantageous for us to talk about autoencoders as probabilistic models - since our notation follows that of a probabilistic framework
    \item Further, VAE's introduced by Kingma et al. were introduced in a probabilistic framework, this is why we cite him, when introducing autoencoders in a probabilistic framework. 
    \begin{quote}
    \textit{probabilistic encoder} cite\{kingma2013auto\}, $q_\phi(z|x)$, conditioned on observed samples, and a second \textit{probabilistic decoder} cite\{kingma2013auto\}
    \end{quote}
    Kingma et al. introduce autoencoders as follows:
    \begin{quote}
        learning a \textit{probabilistic encoder} cite\{kingma2013auto\}, $q_\phi(z|x)$, conditioned on observed samples, and a second \textit{probabilistic decoder} cite\{kingma2013auto\},
    \end{quote} 
\end{itemize}

{\color{blue}
5. Section I.A. Last paragraph. It may be worth to add some references here.} \newline
We have added references as follows:
\begin{quote}
    In some situations the encoding distribution is chosen rather than learned cite\{bengio2013generalized\}, in other situations the encoder and decoder are learned simultaneously cite\{kingma2013auto, makhzani2015adversarial, im2015denoising\}
\end{quote}

{\color{blue}
6. Please use the same tense citing other works: "Bengio at al. [4] treat...", "Im at al. [8] showed...", "Im et al. [8] do not address...", "Makhzani et al. [13] introduced..."}
TODO!!

{\color{blue}
7. Organisation of the paper. It is not clear why denoising autoencoders are reviewed in "Background" section whereas adversarial autoencoders are reviewed in "Related work" section.}

\begin{itemize}
    \item Autoencoders are a more general framework
    \item We specifically build on Adversarial autoencoders.
\end{itemize}

{\color{blue}
8. Section I.C. Last paragraph looks a bit odd especially given the first paragraph of Section I.D}

\begin{itemize}
    \item At the end of section I.C. we are referring to the original VAE paper hence the citation to Kingma et al. - we are pointing out that they do not use denoising.
    \item At the start of section I.D. we are beginning to introduce the work of Im et al. Cited in paragraph two if Section I.D. who introduce DVAEs.
    \item TODO?
\end{itemize}

{\color{blue}
9. Section II.A. It is unclear why it is the only section uses notation w and v instead of x and z, moreover w and v are undefined}

\begin{itemize}
    \item The use of $v$ and $w$ instead of $x$ and $z$ was done deliberately.
    \item Adversarial training is usually performed on data samples, $x$ rather than on latent samples, $z$. If we introduced adversarial training on the data, but then applied it to the latent this may have cause confusion in notation. If we had introduced directly for the latent, readers familiar with adversarial training may have been confused. 
    \item For these reasons we deliberately introduce adversarial training with a general notation. 
    \item We wanted to avoid calling samples, $w$ data samples and sample, $v$ latent samples. Instead we refer to samples $w$ as being from a "target distribution".
    \item In our revised version we refer to $v$ samples as "input samples" coming from our chosen prior distribution $p(v)$ and generated $w$ samples as "output samples". We now say:
    
    \begin{quote}
        produce output samples, $w$ that match a target probability distribution $t(w)$. \newline ... \newline
        The generative model - fed with input samples $v$, drawn from a chosen prior distribution, $p(v)$ - is trained to generate output samples $w$ that are indistinguishable from target $w$ samples  
    \end{quote}
\end{itemize}

{\color{blue}
10. Section IV.B. Second paragraph. "... we used PREVIOUSLY in Algorithm 2 of the Appendix..." - this is the first time this algorithm is mentioined and "previously" implies that a reader should have already been aware of it}
\begin{itemize}
    \item This was an error. We were referring to the wrong algorithm. To make this more clear, we describe the sampling process that we are referring to in the text. We now say:
    \begin{quote}
        To ensure that we draw novel data samples, we do not want to draw samples from the training data at any point during sample synthesis. This means that we cannot use data samples from our training or test data to approximately draw latent samples, $z$ from $\tilde{q}_\phi(z|x)$.
    \end{quote} 
\end{itemize}

{\color{blue}
11. Theorem IV.3 formulation. "sufficient approximation" is ambiguous}
\begin{itemize}
    \item We have changed this to:
    \begin{quote}
        Assuming that $p_\theta(x|z)$ is approximately equal to $\mathcal{P}(x|z)$,
    \end{quote}
\end{itemize}

{\color{blue}
12. Section V. "We represent an image in the form of a 3D array" - Does it mean the RGB representation?}
\begin{itemize}
    \item It means, $C \times W \times H$, $C$ - colour channel (would be 1 for grey scale), $W$ - width of the image, $H$ - height of the image.
    \item We clarify this, making the following changes:
    \begin{quote}
        We represent an image in the form of a $3$D array (colour channels $\times$ width $\times$ height);
    \end{quote}
\end{itemize}

{\color{blue}
13. Section V.A. Last paragraph. It would be better to add some discussion about fundamental difference between encoder and decoder that lead to this.}

\begin{itemize}
    \item This is not related to the fundamental difference between encoder and decoder, but because the "reconstruction loss" is minimised, which does not take into account the prior $p(z)$.
    \item anything else TODO?
\end{itemize}

{\color{blue}
14. Algorithm 1. For clearer representation it may be better to include both iDAAE and DAAE in the Algorithm with the difference in Line 11}

\begin{itemize}
    \item We have considered this - however we do not see a tidy way to combine both algorithms in one and we would not like readers to be confused by writing the algorithms together.
    \item We think it is better to present one algorithm for the iDAAE and explain that by changing line 11 we obtain the algorithm for the DAAE, as we do already:
    \begin{quote}
        Algorithm 1 shows the steps taken to train an iDAAE. To train a DAAE instead, all lines in Algorithm 1 are the same except Line $11$, which may be replaced by $z_{fake} = E_\phi(\tilde{x})$.
    \end{quote}
\end{itemize}

{\color{blue}
15. Section V. Last paragraph. "... non-denoising adversarial autoencoders" -> "... non-denoising adversarial autoencoders AAE [13]"} \newline

We have done this

{\color{blue}
16. Section VI.B.2. The only datasets where the colour scheme of images is not mentioned} \newline

We have added the following: 
\begin{quote}
     Each example in the dataset is $105$-by-$105$ pixels, taking values \{0,1\}. 
\end{quote}

{\color{blue}
17. Section VI.C. It is unclear why 10-GMM prior is chosen only for DAAE and not for iDAAE} \newline

\begin{itemize}
    \item ...TODO? 
\end{itemize}

{\color{blue}
18. Section VI.C. Which optimisation algorithm is used for training?}
\begin{itemize}
    \item To ensure that our experiments are repeatable we have provided code: \url{https://github.com/ToniCreswell/DAAE_/blob/master/DAAE_sprite_v2.ipynb}
    \item We use adam
    \item We have added the following:
    \begin{quote}
        In order to compare models trained on the same datasets, the same network architectures, batch size, learning rate, annealing rate, size of latent code and number of epochs is used for each. All modes were trained using the Adam cite\{kingma2014adam\} optimisation algorithm.
    \end{quote}
\end{itemize}

19. Section VI.D. The first sentence makes it unclear that for AAE images are not corrupted and the following statements that for AAE uncorrupted images are used are confusing
20. Tables III and IV. "200D Gaussian" is placed such that it was used only for DAAE, moreover in the following tables "200D Gaussian" is repeated for each row
21. Section VI.D.1. It would be better to have more discussion about why the performance on MNIST of the proposed methods is worse than AAE's.
22. Section VI.E. It is claimed that "if we pass samples from the prior through the decoder of a trained DAAE, the samples are likely to be inconsistent with the training data". It would be interesting to see this in practise. There are results with $z^{(0)}$, but they are taken from some other distribution rather than from the prior.
23. Section VI.E. It is better to stick with the same order of the datasets for all the tasks
24. Section VI.E.3. Phrases "less negative log-likelihood" and "more negative" are very confusing, as it seems like log-likelihood is still used whereas "negative log-likelihood" is another popular measure. It is better to just say "larger" and "smaller"
25. Section VI.F.1. Second paragraph, first sentence implies that there will be "second" with discussion DAAE with 2D 10-GMM
26. Section VI.G. It would be good to provide time estimates here to understand how much longer iDAAE takes to train
27. Section VII. First two paragraphs can be safely skipped.
28. References. It is better to cite published version of the works rather than their preprints from arxiv, like in [8] - Proceeding of the 31 AAAI Conference on Artificial Intelligence, or in [9] arXiv reference is redundant
29. Appendix A. It is odd to use different names for the same lemmas as in the main body of the paper.
30. Appendix A. Proof of Lemma A.1. "Similar to proof in Bengio [3]" looks like it was not supposed to be there.
31. Appendix A. There is no point to state the theorem here as its proof has been provided in the main body of the paper. 

Minor notes:
1. Page 1, left column, row 24. "...encoded data in THE latent space" - missing article
2. Caption for Figure 1. All the models are mentioned both with their names and acronyms except Denoising Variational Autoencoders
3. Page 2, left column, rows 30-32. "Methods to sample denoising adversarial autoencoders through Markov-Chain sampling". Should they sample synthetic data points rather than autoencoders?
4. Page 3, left column, rows 9-12. "In the second step, a random variable ... the Hadamard product" - missing verb
5. Page 3, left column, row 33. "... may be formed in the following two ways" - "two ways" are not very clear
6. Page 5, left column, row 37. "This will be come ..." -> "This will become ..."
7. Page 5, right column, row 48 (and the same for Appendix). "... the sampling process in 2" -> "... the sampling process in (2)"
8. Page 5, right column, row 52 (and the same for Appendix). "... by the transition operator, $T_{\theta, \phi}(z_{t+1}|z_t)$" -> "... by the transition operator, $T_{\theta, \phi}(z_{t+1}|z_t) (3)$"
9. Page 8, left column, row 7. "Prior indicated..." -> "Prior indicates..."
10. Page 13, left column, row 23. Should it be "testing dataset"?


\end{document}
